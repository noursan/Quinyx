{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load the necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fetch the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.getcwd()\n",
    "data_file = 'VesselData.xlsx'\n",
    "data = pd.read_excel(data_path + '/' + data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eta</th>\n",
       "      <th>ata</th>\n",
       "      <th>atd</th>\n",
       "      <th>vesseldwt</th>\n",
       "      <th>vesseltype</th>\n",
       "      <th>discharge1</th>\n",
       "      <th>load1</th>\n",
       "      <th>discharge2</th>\n",
       "      <th>load2</th>\n",
       "      <th>discharge3</th>\n",
       "      <th>...</th>\n",
       "      <th>load4</th>\n",
       "      <th>stevedorenames</th>\n",
       "      <th>hasnohamis</th>\n",
       "      <th>earliesteta</th>\n",
       "      <th>latesteta</th>\n",
       "      <th>traveltype</th>\n",
       "      <th>previousportid</th>\n",
       "      <th>nextportid</th>\n",
       "      <th>isremarkable</th>\n",
       "      <th>vesselid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-09-19 00:00:00+00</td>\n",
       "      <td>2017-09-19 00:00:00+00</td>\n",
       "      <td>2017-09-22 00:00:00+00</td>\n",
       "      <td>109290.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90173.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stevedore_104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-09-19 00:00:00+00</td>\n",
       "      <td>2017-09-19 00:00:00+00</td>\n",
       "      <td>ARRIVAL</td>\n",
       "      <td>981.0</td>\n",
       "      <td>731.0</td>\n",
       "      <td>f</td>\n",
       "      <td>2242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-10-02 00:00:00+00</td>\n",
       "      <td>2017-10-02 00:00:00+00</td>\n",
       "      <td>2017-10-03 00:00:00+00</td>\n",
       "      <td>67170.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stevedore_109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-10-02 00:00:00+00</td>\n",
       "      <td>2017-10-02 00:00:00+00</td>\n",
       "      <td>ARRIVAL</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>f</td>\n",
       "      <td>5462.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-09-30 00:00:00+00</td>\n",
       "      <td>2017-09-30 00:00:00+00</td>\n",
       "      <td>2017-10-01 00:00:00+00</td>\n",
       "      <td>67737.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stevedore_57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-09-30 00:00:00+00</td>\n",
       "      <td>2017-09-30 00:00:00+00</td>\n",
       "      <td>ARRIVAL</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>f</td>\n",
       "      <td>5251.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-10-02 00:00:00+00</td>\n",
       "      <td>2017-10-02 00:00:00+00</td>\n",
       "      <td>2017-10-03 00:00:00+00</td>\n",
       "      <td>43600.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stevedore_57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-10-02 00:00:00+00</td>\n",
       "      <td>2017-10-02 00:00:00+00</td>\n",
       "      <td>ARRIVAL</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>f</td>\n",
       "      <td>5268.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-10-02 00:00:00+00</td>\n",
       "      <td>2017-10-02 00:00:00+00</td>\n",
       "      <td>2017-10-02 00:00:00+00</td>\n",
       "      <td>9231.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stevedore_98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-10-02 00:00:00+00</td>\n",
       "      <td>2017-10-02 00:00:00+00</td>\n",
       "      <td>ARRIVAL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>f</td>\n",
       "      <td>5504.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      eta                     ata                     atd  \\\n",
       "0  2017-09-19 00:00:00+00  2017-09-19 00:00:00+00  2017-09-22 00:00:00+00   \n",
       "1  2017-10-02 00:00:00+00  2017-10-02 00:00:00+00  2017-10-03 00:00:00+00   \n",
       "2  2017-09-30 00:00:00+00  2017-09-30 00:00:00+00  2017-10-01 00:00:00+00   \n",
       "3  2017-10-02 00:00:00+00  2017-10-02 00:00:00+00  2017-10-03 00:00:00+00   \n",
       "4  2017-10-02 00:00:00+00  2017-10-02 00:00:00+00  2017-10-02 00:00:00+00   \n",
       "\n",
       "   vesseldwt  vesseltype  discharge1  load1  discharge2  load2  discharge3  \\\n",
       "0   109290.0         5.0         0.0    0.0         0.0    0.0     90173.0   \n",
       "1    67170.0         3.0         0.0    0.0         0.0    0.0         0.0   \n",
       "2    67737.0         3.0         0.0    0.0         0.0    0.0         0.0   \n",
       "3    43600.0         3.0         0.0    0.0         0.0    0.0         0.0   \n",
       "4     9231.0         3.0         0.0    0.0         0.0    0.0         0.0   \n",
       "\n",
       "   ...  load4  stevedorenames  hasnohamis             earliesteta  \\\n",
       "0  ...    0.0   Stevedore_104         NaN  2017-09-19 00:00:00+00   \n",
       "1  ...    0.0   Stevedore_109         NaN  2017-10-02 00:00:00+00   \n",
       "2  ...    0.0    Stevedore_57         NaN  2017-09-30 00:00:00+00   \n",
       "3  ...    0.0    Stevedore_57         NaN  2017-10-02 00:00:00+00   \n",
       "4  ...    0.0    Stevedore_98         NaN  2017-10-02 00:00:00+00   \n",
       "\n",
       "                latesteta traveltype previousportid nextportid  isremarkable  \\\n",
       "0  2017-09-19 00:00:00+00    ARRIVAL          981.0      731.0             f   \n",
       "1  2017-10-02 00:00:00+00    ARRIVAL           19.0       15.0             f   \n",
       "2  2017-09-30 00:00:00+00    ARRIVAL           19.0       19.0             f   \n",
       "3  2017-10-02 00:00:00+00    ARRIVAL           15.0       18.0             f   \n",
       "4  2017-10-02 00:00:00+00    ARRIVAL           74.0       27.0             f   \n",
       "\n",
       "   vesselid  \n",
       "0    2242.0  \n",
       "1    5462.0  \n",
       "2    5251.0  \n",
       "3    5268.0  \n",
       "4    5504.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test data has 8208 rows and 22 columns\n"
     ]
    }
   ],
   "source": [
    "print(f'The test data has {data.shape[0]} rows and {data.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8208 entries, 0 to 8207\n",
      "Data columns (total 22 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   eta             8208 non-null   object \n",
      " 1   ata             8208 non-null   object \n",
      " 2   atd             8208 non-null   object \n",
      " 3   vesseldwt       8206 non-null   float64\n",
      " 4   vesseltype      8208 non-null   float64\n",
      " 5   discharge1      8208 non-null   float64\n",
      " 6   load1           8208 non-null   float64\n",
      " 7   discharge2      8208 non-null   float64\n",
      " 8   load2           8208 non-null   float64\n",
      " 9   discharge3      8208 non-null   float64\n",
      " 10  load3           8208 non-null   float64\n",
      " 11  discharge4      8208 non-null   float64\n",
      " 12  load4           8208 non-null   float64\n",
      " 13  stevedorenames  8206 non-null   object \n",
      " 14  hasnohamis      0 non-null      float64\n",
      " 15  earliesteta     8208 non-null   object \n",
      " 16  latesteta       8208 non-null   object \n",
      " 17  traveltype      8208 non-null   object \n",
      " 18  previousportid  8208 non-null   float64\n",
      " 19  nextportid      8208 non-null   float64\n",
      " 20  isremarkable    8208 non-null   object \n",
      " 21  vesselid        8208 non-null   float64\n",
      "dtypes: float64(14), object(8)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now look for missing or duplicated data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing(dataset):\n",
    "    \n",
    "    num_missing_percol = dataset.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "    col_with_missing = num_missing_percol[num_missing_percol > 0]\n",
    "    percentage = col_with_missing/dataset[col_with_missing.index].shape[0]\n",
    "\n",
    "    df_missing = pd.concat([col_with_missing, round(percentage*100,1)], keys = ['Missing Values', 'Percentage %'], axis = 1)\n",
    "\n",
    "    return df_missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>Percentage %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hasnohamis</th>\n",
       "      <td>8208</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vesseldwt</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stevedorenames</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Missing Values  Percentage %\n",
       "hasnohamis                8208         100.0\n",
       "vesseldwt                    2           0.0\n",
       "stevedorenames               2           0.0"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_missing(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_duplicates(dataset):\n",
    "    duplicates = dataset[dataset.duplicated()]\n",
    "    print(f'There are {len(duplicates)} duplicates.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 duplicates.\n"
     ]
    }
   ],
   "source": [
    "check_duplicates(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove the rows with missing values as well as the column with plently of missing data. Furthermore, we remove the date time variables to simplify the problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['hasnohamis', 'eta','ata','atd', 'earliesteta', 'latesteta'], axis=1, inplace=True)\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now fix the type of some features: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list = ['vesseltype', 'previousportid', 'nextportid', 'vesselid']\n",
    "data[var_list] = data[var_list].astype('object') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vesseldwt         float64\n",
       "vesseltype         object\n",
       "discharge1        float64\n",
       "load1             float64\n",
       "discharge2        float64\n",
       "load2             float64\n",
       "discharge3        float64\n",
       "load3             float64\n",
       "discharge4        float64\n",
       "load4             float64\n",
       "stevedorenames     object\n",
       "traveltype         object\n",
       "previousportid     object\n",
       "nextportid         object\n",
       "isremarkable       object\n",
       "vesselid           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look again at the final shape of our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test data has 8204 rows and 16 columns\n"
     ]
    }
   ],
   "source": [
    "print(f'The test data has {data.shape[0]} rows and {data.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create new features containing the total transships:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['transships1'] = data['discharge1'] + data['load1']\n",
    "data['transships2'] = data['discharge2'] + data['load2']\n",
    "data['transships3'] = data['discharge2'] + data['load3']\n",
    "data['transships4'] = data['discharge4'] + data['load4']\n",
    "data['ts'] = list(zip(data['transships1'], data['transships2'], data['transships3'], data['transships4']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.columns.drop(list(data.filter(regex='discharge')))]\n",
    "data = data[data.columns.drop(list(data.filter(regex='load')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= data.pop('ts')\n",
    "data_train, data_test, y_train, y_test = train_test_split(data, y, train_size=0.8, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1 = data_train.pop('transships1')\n",
    "y_2 = data_train.pop('transships2')\n",
    "y_3 = data_train.pop('transships3')\n",
    "y_4 = data_train.pop('transships4') \n",
    "\n",
    "data_test = data_test[data_test.columns.drop(list(data_test.filter(regex='transships')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vesseldwt         float64\n",
       "vesseltype         object\n",
       "stevedorenames     object\n",
       "traveltype         object\n",
       "previousportid     object\n",
       "nextportid         object\n",
       "isremarkable       object\n",
       "vesselid           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_ft = data_train.select_dtypes('object').columns\n",
    "num_ft = data_train.select_dtypes('float64').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply one-hot encoder to each column with categorical data\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "train_encoded = pd.DataFrame(encoder.fit_transform(data_train[cat_ft]))\n",
    "test_encoded = pd.DataFrame(encoder.transform(data_test[cat_ft]))\n",
    "\n",
    "# Redefine index\n",
    "train_encoded.index = data_train.index\n",
    "test_encoded.index = data_test.index\n",
    "\n",
    "# Set informative feature names\n",
    "train_encoded.columns = encoder.get_feature_names_out(cat_ft)\n",
    "test_encoded.columns = encoder.get_feature_names_out(cat_ft)\n",
    "\n",
    "# Fetch numerical variable\n",
    "num_train = data_train.drop(cat_ft, axis=1)\n",
    "num_test = data_test.drop(cat_ft, axis=1)\n",
    "\n",
    "# Add one-hot encoded categorical data to numerical features\n",
    "train_encoded = pd.concat([num_train, train_encoded], axis=1)\n",
    "test_encoded = pd.concat([num_test, test_encoded], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "train_scaled= pd.DataFrame(scaler.fit_transform(train_encoded[num_ft]))\n",
    "test_scaled= pd.DataFrame(scaler.transform(test_encoded[num_ft]))\n",
    "\n",
    "# Redefine index\n",
    "train_scaled.index = train_encoded.index\n",
    "test_scaled.index = test_encoded.index\n",
    "\n",
    "train_scaled.columns = num_ft\n",
    "test_scaled.columns = num_ft\n",
    "\n",
    "# Fetch encoded features \n",
    "cat_train = train_encoded.drop(num_ft, axis=1)\n",
    "cat_test = test_encoded.drop(num_ft, axis=1)\n",
    "\n",
    "# Add scaled numerical variables to encoded features\n",
    "train_prep = pd.concat([cat_train, train_scaled], axis=1)\n",
    "test_prep = pd.concat([cat_test, test_scaled], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vesseldwt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.563000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-3.247948e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000076e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-7.194255e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.034512e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-4.794618e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.728163e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.494227e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          vesseldwt\n",
       "count  6.563000e+03\n",
       "mean  -3.247948e-17\n",
       "std    1.000076e+00\n",
       "min   -7.194255e-01\n",
       "25%   -6.034512e-01\n",
       "50%   -4.794618e-01\n",
       "75%    1.728163e-01\n",
       "max    5.494227e+00"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prep[num_ft].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model = LinearRegression().fit(train_prep, y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg_model.predict(test_prep)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ee5c6512742b558c2cbdf00155f3fff2c761cc48804a32254d9533014e48b24c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ds': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
